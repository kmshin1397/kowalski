# Licensed to the Apache Software Foundation (ASF) under A or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# see org.apache.kafka.clients.consumer.ConsumerConfig for more details

# Sample MirrorMaker 2.0 top-level configuration file
# Run with ./bin/connect-mirror-maker.sh connect-mirror-maker.properties

# specify any number of cluster aliases
clusters=primary, secondary

# connection information for each cluster
# This is a comma separated host:port pairs for each cluster
# for e.g. "A_host1:9092, A_host2:9092, A_host3:9092"
# primary.bootstrap.servers=localhost:9082
primary.bootstrap.servers=

# secondary in Confluent Cloud
secondary.bootstrap.servers=pkc-4r087.us-west2.gcp.confluent.cloud:9092
secondary.ssl.endpoint.identification.algorithm=https
secondary.security.protocol=SASL_SSL
secondary.sasl.mechanism=PLAIN
secondary.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="" password="";
secondary.request.timeout.ms=20000
secondary.retry.backoff.ms=500
secondary.key.converter=org.apache.kafka.connect.converters.ByteArrayConverter
secondary.value.converter=org.apache.kafka.connect.converters.ByteArrayConverter
secondary.config.storage.topic=connect-configs
secondary.offset.storage.topic=connect-offsets
secondary.status.storage.topic=connect-statuses
secondary.key.converter.schemas.enable=true
secondary.value.converter.schema.enable=true
secondary.offset.flush.interval.ms=10000
secondary.group.id=connect-cluster
secondary.plugin.path=/usr/local/share/java


topics = .*
topics.exclude=.*[\-\.]internal, .*\.replica, __.*

# enable and configure individual replication flows
primary->secondary.enabled = true

# regex which defines which topics gets replicated. For eg "foo-.*"
primary->secondary.topics = ztf_20210421_programid1

# Setting replication factor of newly created remote topics
# secondary.topics.mm2-offsets.primary.internal.replication.factor=1
# primary.topics.mm2-offsets.secondary.internal.replication.factor=1
# test-replicate.replication.factor=3
# config.storage.replication.factor=1
# status.storage.replication.factor=1
# offset.storage.replication.factor=1
replication.factor = 3

# refresh.topics.enabled = true
# sync.topic.configs.enabled = true
# sync.topic.acls.enabled = false
# refresh.topics.interval.seconds = 10
